{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.read_csv(\"evaluation.csv\", delimiter=\"|\")\n",
    "APU = pd.read_csv(\"Uni_Asia_Pacific_1.csv\", delimiter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APU.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation.shape)\n",
    "print(APU.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(APU, evaluation, how='inner', on=[\"itemID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test['itemID'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DF to show the itemID where count is = 1 or = 2\n",
    "df_1 = test.groupby('itemID').filter(lambda x: len(x) == 1)\n",
    "df_2 = test.groupby('itemID').filter(lambda x: len(x) == 2)\n",
    "\n",
    "print(df_1.shape)\n",
    "print(df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicate \n",
    "\n",
    "test.drop_duplicates(subset =\"itemID\", keep='first' ,inplace=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe that are match after merging\n",
    "match_df = pd.merge(test, evaluation, how='inner', on=[\"itemID\"])\n",
    "match_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 370 itemID not match with evaluation CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe that are not match\n",
    "\n",
    "notmatch_df = evaluation[~evaluation.itemID.isin(match_df.itemID)]\n",
    "notmatch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"items.csv\", delimiter=\"|\")\n",
    "transaction = pd.read_csv(\"transactions.csv\", delimiter=\"|\")\n",
    "\n",
    "data = pd.merge(items, transaction, on=[\"itemID\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 368 itemID found in items CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge \n",
    "DF_1 = pd.merge(items, notmatch_df, on=[\"itemID\"])\n",
    "DF_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DF_1['itemID'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 itemID not found in items CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe with itemID that are not found in both evaluation and items csv\n",
    "\n",
    "notmatch_df_1 = evaluation[~evaluation.itemID.isin(DF_1.itemID)&(~evaluation.itemID.isin(match_df.itemID))]\n",
    "notmatch_df_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify whether these 2 itemID are in items\n",
    "\n",
    "#Create dataframe\n",
    "verify_df = pd.merge(items, notmatch_df_1, on=[\"itemID\"])\n",
    "verify_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both itemID are not found in items CSV\n",
    "## So I create csv using \"DF_1\" with 368 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = DF_1.to_csv(\"new_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further optimize submission using new DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_features = pd.read_csv(\"new_df.csv\")\n",
    "new_df_submission =  pd.read_csv(\"new_df.csv\")\n",
    "new_df_submission = new_df_submission.drop(['main topic','subtopics','author','publisher'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseFeature(new_df_features):\n",
    "    data = str(new_df_features[\"main topic\"]) + ','\n",
    "    data += str(new_df_features[\"subtopics\"]) + ','\n",
    "    x = data.replace('[','')\n",
    "    y = x.replace(']','')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_features['parsedFeatureStr'] = new_df_features.apply(parseFeature, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=3, max_features=None,\n",
    "                            strip_accents='unicode', analyzer='word',token_pattern=r',',ngram_range=(1,3),stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedFeatureMatrix = vectorizer.fit_transform(new_df_features['parsedFeatureStr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedFeatureMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import sigmoid_kernel \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "\n",
    "sig = sigmoid_kernel(parsedFeatureMatrix, parsedFeatureMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(new_df_features.index, index = new_df_features['title'])\n",
    "indices_df = pd.Series(new_df_features.index, index = new_df_features['title']).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(title, sig=sig):\n",
    "    index = indices[title]\n",
    "    print(index)\n",
    "    \n",
    "    # get similarity scores\n",
    "    sig_scores = list(enumerate(sig[index]))\n",
    "    #sort by scores\n",
    "    sig_scores = sorted(sig_scores, key=lambda x:x[1], reverse=True)\n",
    "    sig_scores = sig_scores[1:6]\n",
    "    \n",
    "    #relate to book\n",
    "    book_indices = [i[0] for i in sig_scores]\n",
    "    \n",
    "    return new_df_features['itemID'].iloc[book_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec(new_df_submission, num):\n",
    "    recommended_books = []\n",
    "    recommender_df = recommender(new_df_submission['title']).to_frame()\n",
    "    recommender_df = recommender_df.reset_index(drop=True)\n",
    "    for ind,row in recommender_df.iterrows():\n",
    "        recommended_books.append(row['itemID'])\n",
    "        \n",
    "    return recommended_books[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend = ['rec1','rec2','rec3','rec4','rec5']\n",
    "for i in range(0,5):\n",
    "    key = recommend[i]\n",
    "    new_df_submission[key] = new_df_submission.apply(rec,num=i, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_submission = new_df_submission.drop(['title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_submission = new_df_submission.to_csv(\"new_df_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
